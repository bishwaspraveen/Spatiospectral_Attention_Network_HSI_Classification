{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import scipy.ndimage\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv3D, Reshape, BatchNormalization, MaxPooling3D, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam, Adadelta, Adagrad, Adamax\n",
    "from tensorflow.keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "import np_utils\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from keract import get_activations, display_activations\n",
    "from tensorflow import one_hot as to_categorical\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.io as sci\n",
    "import time\n",
    "from sklearn import random_projection as rp\n",
    "#from skimage.filters import gabor, gaussian\n",
    "import scipy\n",
    "import spectral\n",
    "import time\n",
    "import math\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 11\n",
    "testRatio = 0.9\n",
    "valRatio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIndianPinesData():\n",
    "    data = sio.loadmat(r'C:/Users/bishw/OneDrive/Desktop/Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "    labels = sio.loadmat(r'C:/Users/bishw/OneDrive/Desktop/Indian_pines_gt.mat')['indian_pines_gt']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (145, 145, 200)\n",
      "Shape of y : (145, 145)\n"
     ]
    }
   ],
   "source": [
    "X, y = loadIndianPinesData()\n",
    "print (\"Shape of X : \"+str(X.shape))\n",
    "print (\"Shape of y : \"+str(y.shape))\n",
    "\n",
    "#For plotting accuracy plots\n",
    "y_full = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standartizeData(X):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    scaler = preprocessing.StandardScaler()  \n",
    "    newX = scaler.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1],X.shape[2]))\n",
    "    return newX, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bishw\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\bishw\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (145, 145, 200)\n"
     ]
    }
   ],
   "source": [
    "X, scaler = standartizeData(X)\n",
    "print (\"Shape of X : \"+str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPCA(X, numComponents=50):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (145, 145, 50)\n"
     ]
    }
   ],
   "source": [
    "X, pca = applyPCA(X)\n",
    "\n",
    "print (\"Shape of X : \"+str(X.shape))\n",
    "\n",
    "#For plotting accuracy plots\n",
    "X_full = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createPatches(X, y, windowSize=7, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (10249, 11, 11, 50)\n",
      "Shape of y : (10249,)\n"
     ]
    }
   ],
   "source": [
    "X, y = createPatches(X, y, windowSize=windowSize)\n",
    "print (\"Shape of X : \"+str(X.shape))\n",
    "print (\"Shape of y : \"+str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio=0.9):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=345, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=testRatio/(testRatio + valRatio), random_state=345, stratify=y_test)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (1024, 11, 11, 50)\n",
      "Shape of X_test : (8303, 11, 11, 50)\n",
      "Shape of X_val : (922, 11, 11, 50)\n",
      "Shape of y_train : (1024,)\n",
      "Shape of y_test : (8303,)\n",
      "Shape of y_val : (922,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,X_val, y_train, y_test, y_val = splitTrainTestSet(X, y, testRatio)\n",
    "print (\"Shape of X_train : \"+str(X_train.shape))\n",
    "print (\"Shape of X_test : \"+str(X_test.shape))\n",
    "print (\"Shape of X_val : \"+str(X_val.shape))\n",
    "print (\"Shape of y_train : \"+str(y_train.shape))\n",
    "print (\"Shape of y_test : \"+str(y_test.shape))\n",
    "print (\"Shape of y_val : \"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({10.0: 245, 1.0: 143, 13.0: 126, 9.0: 97, 2.0: 83, 5.0: 73, 11.0: 59, 4.0: 48, 7.0: 48, 14.0: 39, 3.0: 24, 12.0: 20, 15.0: 9, 0.0: 5, 6.0: 3, 8.0: 2})\n"
     ]
    }
   ],
   "source": [
    "count = y_train\n",
    "import collections\n",
    "counter=collections.Counter(count)\n",
    "print (counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampleWeakClasses(X, y):\n",
    "    uniqueLabels, labelCounts = np.unique(y, return_counts=True)\n",
    "    maxCount = np.max(labelCounts)\n",
    "    labelInverseRatios = maxCount / labelCounts  \n",
    "    # repeat for every label and concat\n",
    "    newX = X[y == uniqueLabels[0], :, :, :].repeat(round(labelInverseRatios[0]), axis=0)\n",
    "    newY = y[y == uniqueLabels[0]].repeat(round(labelInverseRatios[0]), axis=0)\n",
    "    for label, labelInverseRatio in zip(uniqueLabels[1:], labelInverseRatios[1:]):\n",
    "        cX = X[y== label,:,:,:].repeat(round(labelInverseRatio), axis=0)\n",
    "        cY = y[y == label].repeat(round(labelInverseRatio), axis=0)\n",
    "        newX = np.concatenate((newX, cX))\n",
    "        newY = np.concatenate((newY, cY))\n",
    "    np.random.seed(seed=42)\n",
    "    rand_perm = np.random.permutation(newY.shape[0])\n",
    "    newX = newX[rand_perm, :, :, :]\n",
    "    newY = newY[rand_perm]\n",
    "    return newX, newY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (3950, 11, 11, 50)\n",
      "Shape of X_test : (8303, 11, 11, 50)\n",
      "Shape of X_val : (922, 11, 11, 50)\n",
      "Shape of y_train : (3950,)\n",
      "Shape of y_test : (8303,)\n",
      "Shape of y_val : (922,)\n"
     ]
    }
   ],
   "source": [
    "X_train,  y_train = oversampleWeakClasses(X_train, y_train)\n",
    "print (\"Shape of X_train : \"+str(X_train.shape))\n",
    "print (\"Shape of X_test : \"+str(X_test.shape))\n",
    "print (\"Shape of X_val : \"+str(X_val.shape))\n",
    "print (\"Shape of y_train : \"+str(y_train.shape))\n",
    "print (\"Shape of y_test : \"+str(y_test.shape))\n",
    "print (\"Shape of y_val : \"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({9.0: 291, 1.0: 286, 13.0: 252, 2.0: 249, 6.0: 246, 0.0: 245, 10.0: 245, 8.0: 244, 15.0: 243, 3.0: 240, 4.0: 240, 7.0: 240, 12.0: 240, 11.0: 236, 14.0: 234, 5.0: 219})\n"
     ]
    }
   ],
   "source": [
    "count = y_train\n",
    "import collections\n",
    "counter=collections.Counter(count)\n",
    "print (counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AugmentData(X_train):\n",
    "    for i in range(int(X_train.shape[0]/2)):\n",
    "        patch = X_train[i,:,:,:]\n",
    "        num = random.randint(0,2)\n",
    "        if (num == 0):\n",
    "            \n",
    "            flipped_patch = np.flipud(patch)\n",
    "        if (num == 1):\n",
    "            \n",
    "            flipped_patch = np.fliplr(patch)\n",
    "        if (num == 2):\n",
    "            \n",
    "            no = random.randrange(-180,180,30)\n",
    "            flipped_patch = scipy.ndimage.interpolation.rotate(patch, no,axes=(1, 0),\n",
    "                                                               reshape=False, output=None, order=3, mode='constant', cval=0.0, prefilter=False)\n",
    "    \n",
    "    \n",
    "    patch2 = flipped_patch\n",
    "    X_train[i,:,:,:] = patch2\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (3950, 11, 11, 50)\n",
      "Shape of X_test : (8303, 11, 11, 50)\n",
      "Shape of X_val : (922, 11, 11, 50)\n",
      "Shape of y_train : (3950,)\n",
      "Shape of y_test : (8303,)\n",
      "Shape of y_val : (922,)\n"
     ]
    }
   ],
   "source": [
    "X_train = AugmentData(X_train)\n",
    "print (\"Shape of X_train : \"+str(X_train.shape))\n",
    "print (\"Shape of X_test : \"+str(X_test.shape))\n",
    "print (\"Shape of X_val : \"+str(X_val.shape))\n",
    "print (\"Shape of y_train : \"+str(y_train.shape))\n",
    "print (\"Shape of y_test : \"+str(y_test.shape))\n",
    "print (\"Shape of y_val : \"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_RNN : (3950, 11, 11, 50, 1)\n",
      "Shape of X_test_RNN : (8303, 11, 11, 50, 1)\n",
      "Shape of X_val_RNN : (922, 11, 11, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_RNN = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)\n",
    "X_test_RNN = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], X_test.shape[3], 1)\n",
    "X_val_RNN = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], X_val.shape[3], 1)\n",
    "\n",
    "print (\"Shape of X_train_RNN : \"+str(X_train_RNN.shape))\n",
    "print (\"Shape of X_test_RNN : \"+str(X_test_RNN.shape))\n",
    "print (\"Shape of X_val_RNN : \"+str(X_val_RNN.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_RES : (3950, 11, 11, 50)\n",
      "Shape of X_test_RES : (8303, 11, 11, 50)\n",
      "Shape of X_val_RES : (922, 11, 11, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_RES = X_train\n",
    "X_test_RES = X_test\n",
    "X_val_RES = X_val\n",
    "\n",
    "print (\"Shape of X_train_RES : \"+str(X_train_RES.shape))\n",
    "print (\"Shape of X_test_RES : \"+str(X_test_RES.shape))\n",
    "print (\"Shape of X_val_RES : \"+str(X_val_RES.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_RNN : (3950, 11, 11, 50, 1)\n",
      "Shape of X_test_RNN : (8303, 11, 11, 50, 1)\n",
      "Shape of X_val_RNN : (922, 11, 11, 50, 1)\n",
      "Shape of X_train_RES : (3950, 11, 11, 50)\n",
      "Shape of X_test_RES : (8303, 11, 11, 50)\n",
      "Shape of X_val_RES : (922, 11, 11, 50)\n",
      "Shape of y_train : (3950, 16)\n",
      "Shape of y_test : (8303, 16)\n",
      "Shape of y_val : (922, 16)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.cast(y_train, tf.int32)\n",
    "y_test = tf.cast(y_test, tf.int32)\n",
    "y_val = tf.cast(y_val, tf.int32)\n",
    "\n",
    "y_train = to_categorical(indices = y_train, depth = 16)\n",
    "y_test = to_categorical(indices = y_test, depth = 16)\n",
    "y_val = to_categorical(indices = y_val, depth = 16)\n",
    "\n",
    "y_train = y_train.numpy()\n",
    "y_test = y_test.numpy()\n",
    "y_val = y_val.numpy()\n",
    "\n",
    "print (\"Shape of X_train_RNN : \"+str(X_train_RNN.shape))\n",
    "print (\"Shape of X_test_RNN : \"+str(X_test_RNN.shape))\n",
    "print (\"Shape of X_val_RNN : \"+str(X_val_RNN.shape))\n",
    "\n",
    "print (\"Shape of X_train_RES : \"+str(X_train_RES.shape))\n",
    "print (\"Shape of X_test_RES : \"+str(X_test_RES.shape))\n",
    "print (\"Shape of X_val_RES : \"+str(X_val_RES.shape))\n",
    "\n",
    "print (\"Shape of y_train : \"+str(y_train.shape))\n",
    "print (\"Shape of y_test : \"+str(y_test.shape))\n",
    "print (\"Shape of y_val : \"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 11, 11, 50)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 11, 11, 50, 1 0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 11, 11, 26, 1 26          reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 11, 11, 1, 1) 27          conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 121)          0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 121)          0           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 11, 11, 1)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2 (TensorFlowO [(None, 11, 11, 50)] 0           reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 11, 11, 50)   0           tf_op_layer_Tile_2[0][0]         \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 11, 11, 50)   0           multiply_5[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 32)   14432       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 11, 11, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 64)   18496       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 64)   3264        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 11, 11, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 11, 11, 64)   0           conv2d_20[0][0]                  \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 64)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 5, 5, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 5, 5, 32)     18464       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 5, 5, 32)     128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 11, 11, 50,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 5, 5, 32)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 9, 9, 19, 16) 4624        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 5, 5, 64)     18496       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d_2 (AveragePoo (None, 4, 4, 9, 16)  0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 5, 5, 64)     4160        average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 5, 5, 64)     256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 2, 2, 2, 32)  36896       average_pooling3d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 5, 5, 64)     0           conv2d_23[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 256)          0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 5, 5, 64)     0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 256, 1)       0           flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 5, 5, 32)     18464       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 256, 1)       24          reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 5, 5, 32)     128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 256, 1)       24          bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 5, 5, 32)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 256)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 5, 5, 64)     18496       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256)          0           flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 5, 5, 64)     4160        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 5, 5, 64)     256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 256, 1)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 5, 5, 64)     0           conv2d_26[0][0]                  \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 256, 1)       0           reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 5, 5, 64)     0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 256, 1)       0           reshape_8[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 2, 2, 64)     0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 256)          0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 256)          0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 100)          25700       flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 100)          25700       flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 50)           5050        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 50)           5050        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50)           0           dense_13[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 25)           1275        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 25)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           416         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 224,396\n",
      "Trainable params: 223,820\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_RNN_shape = X_train_RNN[0].shape\n",
    "input_RES_shape = X_train_RES[0].shape\n",
    "\n",
    "inputRNN = Input(shape= input_RNN_shape)\n",
    "x = Conv3D(filters=16, kernel_size=(3,3,32), data_format='channels_last')(inputRNN)\n",
    "x = AveragePooling3D(pool_size=(2,2,2), data_format='channels_last')(x)\n",
    "x = Conv3D(filters=32, kernel_size=(3,3,8), data_format='channels_last')(x)\n",
    "x = Flatten()(x)\n",
    "x = Reshape((x.shape[1],1))(x)\n",
    "y = x\n",
    "x = Bidirectional(LSTM(1, return_sequences = True), merge_mode='mul')(x)\n",
    "x = Bidirectional(LSTM(1, return_sequences = True), merge_mode='mul')(x)\n",
    "x = Flatten()(x)\n",
    "x = Activation(activation='softmax')(x)\n",
    "x = Reshape((x.shape[1],1))(x)\n",
    "x = Multiply()([y, x])\n",
    "x = Add()([y, x])\n",
    "x = Flatten()(x)\n",
    "x = Dense(units = 100, activation='relu', kernel_regularizer='l2')(x)\n",
    "x = Dropout(rate = 0.2)(x)\n",
    "x = Dense(units = 50, activation='relu', kernel_regularizer='l2')(x)\n",
    "#x = Dense(units= 16, activation='softmax')(x)\n",
    "modelRNN = Model(inputs=inputRNN, outputs=x)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "inputRES = Input(shape= input_RES_shape)\n",
    "y = inputRES\n",
    "y = Reshape((windowSize,windowSize,50,1))(y)\n",
    "y = Conv3D(filters=1, kernel_size=(1,1,25),activation='relu', data_format='channels_last')(y)\n",
    "y = Conv3D(filters=1, kernel_size=(1,1,26),activation='relu', data_format='channels_last')(y)\n",
    "y = Flatten()(y)\n",
    "y = Activation(activation='softmax')(y)\n",
    "y = Reshape((windowSize,windowSize,1))(y)\n",
    "#y = tf.keras.backend.repeat_elements(y, X_test_RES.shape[3], axis = 3)\n",
    "#y = repeat(y, repeats=X_test_RES.shape[3], axis = -1 )\n",
    "y = tf.tile(input=y, multiples=[1,1,1,X_test_RES.shape[3]])\n",
    "y = multiply([y, inputRES])\n",
    "y = Add()([y, inputRES])\n",
    "\n",
    "#y = Flatten()(y)\n",
    "#y = Dense(units=16, activation='softmax')(y)\n",
    "\n",
    "#First layer of ResNet\n",
    "skip1 = y\n",
    "skip1 = Conv2D(filters = 32, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last')(skip1)\n",
    "skip1 = BatchNormalization()(skip1)\n",
    "skip1 = Activation(activation='relu')(skip1)\n",
    "skip1 = Conv2D(filters = 64, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last')(skip1)\n",
    "skip1 = BatchNormalization()(skip1)\n",
    "y = Conv2D(filters = 64, kernel_size=(1,1), strides=(1,1), padding='same', data_format='channels_last')(y)\n",
    "y = Add()([y, skip1])\n",
    "y = Activation(activation='relu')(y)\n",
    "y = AveragePooling2D(pool_size=(2,2), data_format='channels_last')(y)\n",
    "\n",
    "#Second layer of ResNet\n",
    "skip2 = y\n",
    "skip2 = Conv2D(filters = 32, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last')(skip2)\n",
    "skip2 = BatchNormalization()(skip2)\n",
    "skip2 = Activation(activation='relu')(skip2)\n",
    "skip2 = Conv2D(filters = 64, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last')(skip2)\n",
    "skip2 = BatchNormalization()(skip2)\n",
    "y = Conv2D(filters = 64, kernel_size=(1,1), strides=(1,1), padding='same', data_format='channels_last')(y)\n",
    "y = Add()([y, skip2])\n",
    "y = Activation(activation='relu')(y)\n",
    "#extra addition\n",
    "#y = AveragePooling2D(pool_size=(2,2), data_format='channels_last')(y)\n",
    "\n",
    "#Third layer of ResNet\n",
    "skip3 = y\n",
    "skip3 = Conv2D(filters = 32, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last')(skip3)\n",
    "skip3 = BatchNormalization()(skip3)\n",
    "skip3 = Activation(activation='relu')(skip3)\n",
    "skip3 = Conv2D(filters = 64, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last')(skip3)\n",
    "skip3 = BatchNormalization()(skip3)\n",
    "y = Conv2D(filters = 64, kernel_size=(1,1), strides=(1,1), padding='same', data_format='channels_last')(y)\n",
    "y = Add()([y, skip3])\n",
    "y = Activation(activation='relu')(y)\n",
    "y = AveragePooling2D(pool_size=(2,2), data_format='channels_last')(y)\n",
    "\n",
    "#Dense Layers\n",
    "y = Flatten()(y)\n",
    "y = Dense(units = 100, activation='relu', kernel_regularizer='l2')(y)\n",
    "y = Dropout(rate = 0.2)(y)\n",
    "y = Dense(units= 50, activation='relu', kernel_regularizer='l2')(y)\n",
    "#y = Dense(units= 16, activation='softmax')(y)\n",
    "\n",
    "modelRES = Model(inputs=inputRES, outputs=y)\n",
    "\n",
    "#############################################################################################################################\n",
    "\n",
    "#Bringing the output of both the models together to final dense layers\n",
    "z = add([modelRNN.output, modelRES.output])\n",
    "z = Dense(units = 25, activation='relu', kernel_regularizer='l2')(z)\n",
    "z = Dropout(rate = 0.2)(z)\n",
    "z = Dense(units= y_train.shape[1], activation='softmax')(z)\n",
    "\n",
    "\n",
    "model = Model(inputs=[modelRNN.input, modelRES.input], outputs=z)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001, decay=1e-06)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3950 samples, validate on 922 samples\n",
      "Epoch 1/100\n",
      "3950/3950 [==============================] - 92s 23ms/sample - loss: 6.6339 - accuracy: 0.2656 - val_loss: 6.4923 - val_accuracy: 0.2560\n",
      "Epoch 2/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 5.3627 - accuracy: 0.5208 - val_loss: 5.5057 - val_accuracy: 0.3720\n",
      "Epoch 3/100\n",
      "3950/3950 [==============================] - 71s 18ms/sample - loss: 4.5041 - accuracy: 0.6365 - val_loss: 4.6389 - val_accuracy: 0.5824\n",
      "Epoch 4/100\n",
      "3950/3950 [==============================] - 67s 17ms/sample - loss: 3.8560 - accuracy: 0.7149 - val_loss: 3.8051 - val_accuracy: 0.7299\n",
      "Epoch 5/100\n",
      "3950/3950 [==============================] - 71s 18ms/sample - loss: 3.2907 - accuracy: 0.8035 - val_loss: 3.1490 - val_accuracy: 0.8091\n",
      "Epoch 6/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 2.8247 - accuracy: 0.8661 - val_loss: 2.6303 - val_accuracy: 0.9447\n",
      "Epoch 7/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 2.4872 - accuracy: 0.9063 - val_loss: 2.3010 - val_accuracy: 0.9631\n",
      "Epoch 8/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 2.2171 - accuracy: 0.9357 - val_loss: 2.0442 - val_accuracy: 0.9761\n",
      "Epoch 9/100\n",
      "3950/3950 [==============================] - 61s 15ms/sample - loss: 2.0007 - accuracy: 0.9496 - val_loss: 1.8520 - val_accuracy: 0.9794\n",
      "Epoch 10/100\n",
      "3950/3950 [==============================] - 68s 17ms/sample - loss: 1.8138 - accuracy: 0.9658 - val_loss: 1.6909 - val_accuracy: 0.9826\n",
      "Epoch 11/100\n",
      "3950/3950 [==============================] - 60s 15ms/sample - loss: 1.6755 - accuracy: 0.9618 - val_loss: 1.5647 - val_accuracy: 0.9794\n",
      "Epoch 12/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 1.5367 - accuracy: 0.9689 - val_loss: 1.4353 - val_accuracy: 0.9837\n",
      "Epoch 13/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 1.4172 - accuracy: 0.9722 - val_loss: 1.3217 - val_accuracy: 0.9881\n",
      "Epoch 14/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 1.3017 - accuracy: 0.9762 - val_loss: 1.2296 - val_accuracy: 0.9848\n",
      "Epoch 15/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 1.2033 - accuracy: 0.9795 - val_loss: 1.1487 - val_accuracy: 0.9826\n",
      "Epoch 16/100\n",
      "3950/3950 [==============================] - 60s 15ms/sample - loss: 1.1186 - accuracy: 0.9785 - val_loss: 1.0542 - val_accuracy: 0.9892\n",
      "Epoch 17/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 1.0359 - accuracy: 0.9810 - val_loss: 1.0037 - val_accuracy: 0.9816\n",
      "Epoch 18/100\n",
      "3950/3950 [==============================] - 61s 15ms/sample - loss: 0.9694 - accuracy: 0.9787 - val_loss: 0.9157 - val_accuracy: 0.9848\n",
      "Epoch 19/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 0.9011 - accuracy: 0.9825 - val_loss: 0.8593 - val_accuracy: 0.9870\n",
      "Epoch 20/100\n",
      "3950/3950 [==============================] - 61s 16ms/sample - loss: 0.8408 - accuracy: 0.9838 - val_loss: 0.8017 - val_accuracy: 0.9870\n",
      "Epoch 21/100\n",
      "3950/3950 [==============================] - 60s 15ms/sample - loss: 0.7878 - accuracy: 0.9820 - val_loss: 0.7489 - val_accuracy: 0.9892\n",
      "Epoch 22/100\n",
      "3950/3950 [==============================] - 65s 16ms/sample - loss: 0.7344 - accuracy: 0.9868 - val_loss: 0.7246 - val_accuracy: 0.9837\n",
      "Epoch 23/100\n",
      "3950/3950 [==============================] - 61s 16ms/sample - loss: 0.6945 - accuracy: 0.9866 - val_loss: 0.6611 - val_accuracy: 0.9870\n",
      "Epoch 24/100\n",
      "3950/3950 [==============================] - 65s 17ms/sample - loss: 0.6534 - accuracy: 0.9863 - val_loss: 0.6327 - val_accuracy: 0.9902\n",
      "Epoch 25/100\n",
      "3950/3950 [==============================] - 65s 16ms/sample - loss: 0.6219 - accuracy: 0.9848 - val_loss: 0.5914 - val_accuracy: 0.9892\n",
      "Epoch 26/100\n",
      "3950/3950 [==============================] - 65s 16ms/sample - loss: 0.5848 - accuracy: 0.9891 - val_loss: 0.5626 - val_accuracy: 0.9881\n",
      "Epoch 27/100\n",
      "3950/3950 [==============================] - 66s 17ms/sample - loss: 0.5619 - accuracy: 0.9846 - val_loss: 0.5493 - val_accuracy: 0.9837\n",
      "Epoch 28/100\n",
      "3950/3950 [==============================] - 61s 15ms/sample - loss: 0.5277 - accuracy: 0.9876 - val_loss: 0.5044 - val_accuracy: 0.9881\n",
      "Epoch 29/100\n",
      "3950/3950 [==============================] - 73s 19ms/sample - loss: 0.4950 - accuracy: 0.9919 - val_loss: 0.4917 - val_accuracy: 0.9892\n",
      "Epoch 30/100\n",
      "3950/3950 [==============================] - 65s 17ms/sample - loss: 0.4722 - accuracy: 0.9919 - val_loss: 0.4710 - val_accuracy: 0.9870\n",
      "Epoch 31/100\n",
      "3950/3950 [==============================] - 67s 17ms/sample - loss: 0.4564 - accuracy: 0.9886 - val_loss: 0.4381 - val_accuracy: 0.9892\n",
      "Epoch 32/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 0.4338 - accuracy: 0.9901 - val_loss: 0.4344 - val_accuracy: 0.9892\n",
      "Epoch 33/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 0.4176 - accuracy: 0.9886 - val_loss: 0.4066 - val_accuracy: 0.9913\n",
      "Epoch 34/100\n",
      "3950/3950 [==============================] - 67s 17ms/sample - loss: 0.3947 - accuracy: 0.9916 - val_loss: 0.3945 - val_accuracy: 0.9892\n",
      "Epoch 35/100\n",
      "3950/3950 [==============================] - 64s 16ms/sample - loss: 0.3795 - accuracy: 0.9889 - val_loss: 0.3908 - val_accuracy: 0.9870\n",
      "Epoch 36/100\n",
      "3950/3950 [==============================] - 63s 16ms/sample - loss: 0.3654 - accuracy: 0.9909 - val_loss: 0.3743 - val_accuracy: 0.9881\n",
      "Epoch 37/100\n",
      "3950/3950 [==============================] - 61s 16ms/sample - loss: 0.3518 - accuracy: 0.9916 - val_loss: 0.3538 - val_accuracy: 0.9902\n",
      "Epoch 38/100\n",
      "3950/3950 [==============================] - 83s 21ms/sample - loss: 0.3392 - accuracy: 0.9934 - val_loss: 0.3352 - val_accuracy: 0.9924\n",
      "Epoch 39/100\n",
      "3950/3950 [==============================] - 54s 14ms/sample - loss: 0.3220 - accuracy: 0.9922 - val_loss: 0.3343 - val_accuracy: 0.9892\n",
      "Epoch 40/100\n",
      "3950/3950 [==============================] - 44s 11ms/sample - loss: 0.3104 - accuracy: 0.9944 - val_loss: 0.3247 - val_accuracy: 0.9848\n",
      "Epoch 41/100\n",
      "3950/3950 [==============================] - 34s 9ms/sample - loss: 0.3042 - accuracy: 0.9899 - val_loss: 0.3072 - val_accuracy: 0.9913\n",
      "Epoch 42/100\n",
      "3950/3950 [==============================] - 41s 10ms/sample - loss: 0.2905 - accuracy: 0.9922 - val_loss: 0.2971 - val_accuracy: 0.9935\n",
      "Epoch 43/100\n",
      "3950/3950 [==============================] - 41s 10ms/sample - loss: 0.2807 - accuracy: 0.9932 - val_loss: 0.2926 - val_accuracy: 0.9870\n",
      "Epoch 44/100\n",
      "3950/3950 [==============================] - 39s 10ms/sample - loss: 0.2690 - accuracy: 0.9934 - val_loss: 0.2877 - val_accuracy: 0.9924\n",
      "Epoch 45/100\n",
      "3950/3950 [==============================] - 42s 11ms/sample - loss: 0.2655 - accuracy: 0.9922 - val_loss: 0.2781 - val_accuracy: 0.9902\n",
      "Epoch 46/100\n",
      "3936/3950 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9947"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_train_RNN, X_train_RES], y=y_train, epochs=100, batch_size=32, validation_data=([X_val_RNN, X_val_RES], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x = [X_test_RNN, X_test_RES], y=y_test, batch_size=32)\n",
    "Test_Loss =  score[0]\n",
    "Test_accuracy = score[1]*100\n",
    "print (\"Test Accuracy : \"+str(Test_accuracy))\n",
    "print (\"Test Loss : \"+str(Test_Loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "total = (end-start)/60\n",
    "print (\"Total time : \"+str(total)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='center right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_map (X, y):\n",
    "    Xshape = X\n",
    "    X, y = createPatches(X, y, windowSize=windowSize, removeZeroLabels=False)\n",
    "    X_RNN = X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1)\n",
    "    X_RES = X\n",
    "    prediction = model.predict([X_RNN, X_RES])\n",
    "    prediction = np.argmax(prediction, axis = 1)\n",
    "    \n",
    "    for i in range(0, len(y)):\n",
    "        if (y[i] == 0):\n",
    "            y[i] = 0\n",
    "        elif (y[i] == 16):\n",
    "            y[i] = 17\n",
    "        else :\n",
    "            y[i] = prediction[i]+1\n",
    "            \n",
    "    y = y.reshape((Xshape.shape[0], Xshape.shape[1]))\n",
    "    predict_image = spectral.imshow(classes = y.astype(int),figsize =(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_accuracy_map(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_image = spectral.imshow(classes = y_full.astype(int),figsize =(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
